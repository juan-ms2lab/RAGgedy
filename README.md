# ğŸ§¸ RAGgedy - Your Local AI Assistant

*"Here's to the crazy ones. The misfits. The rebels. The troublemakers. The round pegs in the square holes... Because they change things."*

RAGgedy is for the makers, the tinkerers, and the curious minds who want to chat with their documents without sending data to the cloud. It's a fully local RAG (Retrieval-Augmented Generation) system that runs entirely on your machine.

**Created by [Juan Santos](https://github.com/juan) at [Imagiro](https://github.com/imagiro)**

## âœ¨ What Makes RAGgedy Special

- ğŸ  **Completely Local** - Your documents never leave your computer
- ğŸ§¸ **Friendly Interface** - Clean, intuitive web interface built with Streamlit
- ğŸ¯ **Customizable Personality** - Edit the AI's system prompt to match your style
- ğŸ“š **Smart Document Processing** - Handles PDFs with robust error handling
- ğŸš€ **Real-time Progress** - See exactly what's happening during indexing
- ğŸ” **Powerful Search** - Retrieve up to 50 document chunks for comprehensive answers

## ğŸ’» System Requirements

- **RAM**: 8GB minimum (4GB available for the AI model)
- **Storage**: 10GB free space 
- **OS**: macOS, Linux, or Windows
- **Python**: 3.8 or higher

*RAGgedy is designed to run on typical laptops and desktops - no GPU required!*

## ğŸš€ Quick Start

### 1. Install the Basics
```bash
# Install Ollama (your local LLM server)
brew install ollama  # macOS
# or visit https://ollama.com for other platforms

# Download a language model (this will take a few minutes)
ollama pull phi3:mini

# Install Python dependencies
pip install chromadb pdfplumber sentence-transformers streamlit
```

### 2. Set Up RAGgedy
```bash
# Clone or download this project
git clone [your-repo-url]
cd RAGgedy

# Add your documents to the docs folder
mkdir -p docs
# Copy your PDF or TXT files to docs/

# Build the search index
python build_index.py rebuild docs/

# Launch RAGgedy
streamlit run app.py
```

### 3. Start Chatting!
Open your browser to `http://localhost:8501` and start asking questions about your documents!

## ğŸ¯ Features

### Smart Document Chat
Ask questions about your documents and get answers with source citations. RAGgedy will find relevant passages and use them to provide informed responses.

### Customizable AI Personality
Don't like how RAGgedy responds? Click "ğŸ¯ Customize System Prompt" and change how it talks:
- Make it more formal or casual
- Add domain expertise
- Change the response style
- Set specific constraints

### Real-time Indexing
Watch your documents get processed in real-time with progress bars and status updates. No more wondering if it's working!

### Multiple Models
Choose from different AI models based on your needs:
- `phi3:mini` - Best balance of performance & size (default, ~4GB)
- `tinyllama` - Ultra-fast, minimal resources (~2GB) 
- `gemma2:2b` - Google's efficient model (~3GB)
- `llama2:7b` - More capable but larger (~4.8GB)
- `gpt-oss:20b` - Most capable but requires 16GB+ RAM

## ğŸ“ Project Structure

```
RAGgedy/
â”œâ”€â”€ ğŸ§¸ app.py                 # Main web interface
â”œâ”€â”€ ğŸ“„ extract_and_chunk.py   # Document processing magic
â”œâ”€â”€ ğŸ—ƒï¸ build_index.py         # Vector database management
â”œâ”€â”€ ğŸ“š docs/                  # Put your documents here
â”œâ”€â”€ ğŸ” db/                    # Search index (auto-created)
â””â”€â”€ ğŸ“– README.md              # You are here
```

## ğŸ› ï¸ Advanced Usage

### Command Line Tools

```bash
# Process documents and build index
python build_index.py rebuild docs/

# Query from command line
python build_index.py query "What is machine learning?"

# Check system stats
python build_index.py stats

# Clear the index
python build_index.py clear
```

### Customization

Want to tweak how documents are processed? Edit the settings in the Python files:

```python
# Chunk size (characters per section)
chunk_size = 800

# Overlap between chunks
chunk_overlap = 150

# Number of results to retrieve
top_k = 5
```

## ğŸ”’ Privacy First

RAGgedy was built with privacy in mind:
- âœ… Everything runs locally on your machine
- âœ… No data sent to external services
- âœ… No API keys required
- âœ… Your documents stay private

## ğŸ› Troubleshooting

### "Model not found" error
```bash
ollama pull phi3:mini
```

### "No vector database" error
```bash
python build_index.py rebuild docs/
```

### System running slow?
- Try an even smaller model: `tinyllama` or `gemma2:2b`
- Reduce chunk retrieval count in the interface
- Make sure you have at least 8GB RAM available

## ğŸ¤ Contributing

RAGgedy is for the makers and tinkerers. If you've got ideas, improvements, or just want to make it better, contributions are welcome!

## ğŸ“„ License

RAGgedy is licensed under the [Creative Commons Attribution-NonCommercial 4.0 International License](http://creativecommons.org/licenses/by-nc/4.0/).

**You are free to:**
- âœ… Share and redistribute for non-commercial purposes
- âœ… Adapt, remix, and build upon the material for non-commercial purposes
- âœ… Use for personal projects, education, and research

**Attribution required:** Please credit Juan Santos (Imagiro) and link to this repository.

For commercial licensing, please contact [juan@imagiro.com](mailto:juan@imagiro.com).

## ğŸ’ Acknowledgments

Built with love using:
- [Ollama](https://ollama.com/) - Local LLM inference
- [ChromaDB](https://www.trychroma.com/) - Vector database
- [Streamlit](https://streamlit.io/) - Web interface
- [SentenceTransformers](https://www.sbert.net/) - Text embeddings

**Created with assistance from [Claude AI](https://claude.ai/) by Anthropic**

---

*RAGgedy: Because sometimes you need an AI that's as curious about your documents as you are.* ğŸ§¸